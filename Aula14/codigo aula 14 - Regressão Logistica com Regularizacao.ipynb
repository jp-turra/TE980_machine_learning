{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9623a828",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regressão Logística com Regularização\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Com este código, você irá:\n",
    "- Modificar as funções do nosso código anterior, para agora contemplar a Regularização.\n",
    "- Note que testaremos nosso algoritmo regularizado num novo conjunto de dados que exigirá a adição de termos polinomiais ao modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b54c01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nossa_biblioteca_de_funcoes import *   # Importando as funções auxiliares que usaremos nesse código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9232",
   "metadata": {},
   "source": [
    "Neste código, você implementará a Regressão Logística com Regularização para prever se os microchips de uma fábrica passam num determinado teste de garantia de qualidade (GQ). Durante tal teste de GQ, cada microchip passa por diversos testes que garantem que ele está funcionando corretamente.\n",
    "\n",
    "### Definição do Problema\n",
    "\n",
    "Suponha que você seja o gerente de produto de uma fábrica e você têm acesso aos resultados para dois diferentes testes realizados nos microchips\n",
    "- Destes dois testes, você gostaria de determinar se os chips devem ser aprovados ou rejeitados\n",
    "- Para ajudar na sua tomada de decisão, você tem um banco de dados contendo os resultados de microchips passados. Você usará esses dados para construir um modelo de Regressão Logística\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e641497",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Carregando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67073772",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('dados_microchip.txt') # As duas primeiras colunas referem-se às características -> resultados obtidos pelos microchips nos teste 1 e 2\n",
    "                                   # A terceira (última) coluna refere-se ao resultado do teste de GQ (1 significa chip aprovado)\n",
    "dados = np.loadtxt(file, delimiter=\",\") \n",
    "\n",
    "X_train = dados[:,0:2]\n",
    "y_train = dados[:,-1] # pega apenas a última coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19f90",
   "metadata": {},
   "source": [
    "Vizualizando numericamente os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934ebccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 0.051267  0.69956 ]\n",
      " [-0.092742  0.68494 ]\n",
      " [-0.21371   0.69225 ]\n",
      " [-0.375     0.50219 ]\n",
      " [-0.51325   0.46564 ]]\n",
      "Tipo do X_train: <class 'numpy.ndarray'>\n",
      "y_train: [1. 1. 1. 1. 1.]\n",
      "Tipo do y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print X_train\n",
    "print(\"X_train:\", X_train[:5])\n",
    "print(\"Tipo do X_train:\",type(X_train))\n",
    "\n",
    "# print y_train\n",
    "print(\"y_train:\", y_train[:5])\n",
    "print(\"Tipo do y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f55a3",
   "metadata": {},
   "source": [
    "#### Cheque as dimensões das suas variáveis\n",
    "\n",
    "\n",
    "Uma outra forma útil para se familizarizar com os dados é visualizar suas dimensões.\n",
    "Vamos dar print dos shapes de `X_train` e `y_train`para verificar quantas amostras de treinamento nós temos no nosso conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd374b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O shape de X_train é: (118, 2)\n",
      "O shape de y_train é: (118,)\n",
      "Nós temos 118 exemplos (amostras) de treinamento\n"
     ]
    }
   ],
   "source": [
    "print ('O shape de X_train é: ' + str(X_train.shape))\n",
    "print ('O shape de y_train é: ' + str(y_train.shape))\n",
    "print ('Nós temos %d exemplos (amostras) de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cd102",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plotando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f392f8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = y_train == 1 # identifica os elementos em y que são iguais a 1\n",
    "neg = y_train == 0 # identifica os elementos em y que são iguais a 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "ax.plot(X_train[pos,0], X_train[pos,1], 'k+', label=\"Aprovado\")\n",
    "ax.plot(X_train[neg,0], X_train[neg,1], 'yo', label=\"Reprovado\")\n",
    "\n",
    "#ax.axis([0, 4, 0, 3.5])\n",
    "ax.set_ylabel('Teste 2 no microchip')\n",
    "ax.set_xlabel('Teste 1 no microchip')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd93be5",
   "metadata": {},
   "source": [
    "A figura acima mostra que nosso conjunto de dados não pode ser separado em amostras positivas e negativas usando uma reta. Logo, uma aplicação direta da Regressão Logística não irá performar bem nesse conjunto de dados umas vez que a Regressão Logística não conseguirá encontrar uma Fronteira de Decisão linear adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19759b8",
   "metadata": {},
   "source": [
    "### Mapeamento de características\n",
    "\n",
    "\n",
    "Uma forma de ajustar os dados melhor é criar mais características para cada amostra. Na função `mapeia_caracteristicas`, nós vamos mapear as características para todos os termos polinomiais de $x_1$ e $x_2$ até a sexta potência.\n",
    "\n",
    "$$\\mathrm{mapeia\\_caracteristicas}(x) = \n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_1^2\\\\\n",
    "x_1 x_2\\\\\n",
    "x_2^2\\\\\n",
    "x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1 x_2^5\\\\\n",
    "x_2^6\\end{array}\\right]$$\n",
    "\n",
    "Como um resultado desse mapeamento, nosso vetor de duas características (as pontuações nos dois testes) foi transformado em um vetor de 27 dimensões.\n",
    "- Um classificador de regressão logística treinado para essa dimensão elevada terá uma fronteira de decisão complexa e será não linear ao plotarmos ela num gráfico com 2 dimensões.\n",
    "- A função `mapeia_caracteristicas` está sendo fornecida (não é necessário programá-la) dentro do arquivo nossa_biblioteca_de_funcoes.py. \n",
    "- Visite o arquivo nossa_biblioteca_de_funcoes.py para ver como a função `mapeia_caracteristicas` foi escrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a1730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original dos dados: (118, 2)\n",
      "Shape após o mapeamento de características: (118, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape original dos dados:\", X_train.shape)\n",
    "\n",
    "mapped_X =  mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "print(\"Shape após o mapeamento de características:\", mapped_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a788b",
   "metadata": {},
   "source": [
    "Vamos também plotar os primeiros elementos de `X_train` e `mapped_X` para vermos a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbd5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0.051267 0.69956 ]\n",
      "mapped X_train[0]: [5.12670000e-02 6.99560000e-01 2.62830529e-03 3.58643425e-02\n",
      " 4.89384194e-01 1.34745327e-04 1.83865725e-03 2.50892595e-02\n",
      " 3.42353606e-01 6.90798869e-06 9.42624411e-05 1.28625106e-03\n",
      " 1.75514423e-02 2.39496889e-01 3.54151856e-07 4.83255257e-06\n",
      " 6.59422333e-05 8.99809795e-04 1.22782870e-02 1.67542444e-01\n",
      " 1.81563032e-08 2.47750473e-07 3.38066048e-06 4.61305487e-05\n",
      " 6.29470940e-04 8.58939846e-03 1.17205992e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"mapped X_train[0]:\", mapped_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96b9dd",
   "metadata": {},
   "source": [
    "Uma vez que o mapeamento de características nos permite construir um classificador mais expressivo, ele também está mais suscetível ao overfitting. Para lidar com esse problema, a seguir nós implementamos o método de Regressão Logística com Regularização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40f6d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Função Custo com Regularização\n",
    "\n",
    "Na Regressão Logística com regularização, a função custo tem a forma \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2 \\tag{1}$$\n",
    "\n",
    "onde    \n",
    "*  m é o número de amostras de treinamento, n é o número de características e:\n",
    "$$\n",
    "\\begin{align}\n",
    "  f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) &= g(z^{(i)})\\tag{3} \\\\\n",
    "  z^{(i)} &= \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+ b\\tag{4} \\\\\n",
    "  g(z^{(i)}) &= \\frac{1}{1+e^{-z^{(i)}}}\\tag{5} \n",
    "\\end{align}\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64a3ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Descrição do Código abaixo:\n",
    "\n",
    "A função `calcula_custo_RegLog` abaixo faz um loop passando por todas as amostras e calculando a perda para cada exemplo.\n",
    "O total então é computado e depois divido por m. Por fim, o termo relativo à Regularização é adicionado\n",
    "\n",
    "Note que as variáveis X e y não são escalares mas sim matrizes de shape ($m, n$) e ($𝑚$,) respectivamente, onde  $𝑛$ é o número de características e $𝑚$ é o número de amostras de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63409143",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcula_custo_RegLog_com_regu(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Calcula a função custo para Regressão Logística com Regularização\n",
    "\n",
    "    Argumentos:\n",
    "      X (ndarray (m,n)): Dados, m exemplos com n características\n",
    "      y (ndarray (m,)) : valores alvo\n",
    "      w (ndarray (n,)) : parâmetros do modelo  \n",
    "      b (escalar)      : parâmetro do modelo\n",
    "      lambda_ : (escalar, float):    Controla a quantidade de regularização presente no modelo (default = 1)\n",
    "      \n",
    "    Retorna:\n",
    "      custo (escalar): custo\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]\n",
    "    custo = 0.0\n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i],w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        custo +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)\n",
    "         \n",
    "    custo = custo / m\n",
    "    \n",
    "    # Abaixo calculamos o termo (custo) associado à regularização:\n",
    "    custo_reg =  (lambda_/(2 * m))*sum(np.square(w))\n",
    "            \n",
    "    custo = custo + custo_reg\n",
    "    \n",
    "    return custo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d49986",
   "metadata": {},
   "source": [
    "Rode o código abaixo para checar a nossa implementação da função `calcula_custo_RegLog_com_regu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b836732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo regularizado : 0.6618252552483948\n"
     ]
    }
   ],
   "source": [
    "X_mapped = mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5  # O que este comando faz?\n",
    "initial_b = 0.5\n",
    "lambda_   = 0.5\n",
    "custo     = calcula_custo_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(\"Custo regularizado :\", custo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8a41a",
   "metadata": {},
   "source": [
    "**Resultado esperado**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo regularizado : <b></td>\n",
    "    <td> 0.6618252552483948 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da3ef7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Método do Gradiente com Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25268a92",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Lembre-se que o Método do Gradiente implementa a seguinte lógica:\n",
    "$$\\begin{align*}\n",
    "&\\text{repetir até convergir:} \\; \\lbrace \\\\\n",
    "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{para j := 0..n-1} \\\\ \n",
    "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\\\\n",
    "&\\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "Onde cada iteração performa atualização simultanea de $w_j$ para todo $j$ e para $b$, onde\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\left( \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j  \\tag{2} \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3} \n",
    "\\end{align*}$$\n",
    "\n",
    "* $f_{\\mathbf{w},b}(x^{(i)})$ é a previsão feita pelo modelo, sendo $y^{(i)}$ o alvo\n",
    "* Para o modelo de Regressão Logística:\n",
    "    $z = \\mathbf{w} \\cdot \\mathbf{x} + b$  \n",
    "    $f_{\\mathbf{w},b}(x) = g(z)$  \n",
    "    sendo $g(z)$ a função sigmoide:  \n",
    "    $g(z) = \\frac{1}{1+e^{-z}}$   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f868b74",
   "metadata": {},
   "source": [
    "## Implementação do Método do Gradiente:\n",
    "\n",
    "O algoritmo do Método do Gradiente possui duas componentes: \n",
    "- O loop que implementa a equação (1) acima. Essa é a função metodo_do_gradiente_RegLog_com_regu abaixo.\n",
    "- O cálculo do gradiente atual, dado pelas equações (2) e (3) acima. Essa é a função calcula_gradiente_RegLog_com_regu abaixo.\n",
    "\n",
    "#### Cálculo do gradiente: descrição do código:\n",
    "Implementa as equações (2) e (3) acima para todo $w_j$ e $b$.\n",
    "\n",
    "Há muitas formas para se implementar isso. Abaixo fazemos da seguinte maneira:\n",
    "- Inicializamos as variáveis para acumular `dj_dw` e `dj_db`\n",
    "- Para cada exemplo:\n",
    "    - Calcula-se o erro para esse exemplo, $g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b) - \\mathbf{y}^{(i)}$\n",
    "    - Para cada valor de entrada $x_{j}^{(i)}$ nesse exemplo,  \n",
    "        - multiplica o erro pela entrada  $x_{j}^{(i)}$, e adiciona ao elemento correspondente de `dj_dw`. (Equação 2 acima)\n",
    "    - adiciona o erro para `dj_db` (Equação 3 acima)\n",
    "\n",
    "- divide-se `dj_db` e `dj_dw` pelo número total de amostras (m)\n",
    "- Note que $\\mathbf{x}^{(i)}$ em Numpy é `X[i,:]` ou `X[i]`  e que $x_{j}^{(i)}$ é `X[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05ef97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_gradiente_RegLog_com_regu(X, y, w, b, lambda_ = 1): \n",
    "    \"\"\"\n",
    "    Calcula Gradiente para Regressão Linear\n",
    "    Argumentos:\n",
    "      X (ndarray (m,n)): Dados, contendo m exemplos com n características\n",
    "      y (ndarray (m,)) : valores alvo\n",
    "      w (ndarray (n,)) : parâmetros w do modelo  \n",
    "      b (scalar)       : parâmetro b do modelo\n",
    "      lambda_ : (escalar, float):    Controla a quantidade de regularização presente no modelo (default = 1)\n",
    "      \n",
    "    Retorna:\n",
    "      dj_dw (ndarray (n,)): O gradiente da função custo com relação aos parâmetros w. \n",
    "      dj_db (escalar):      O gradiente da função custo com relação ao parâmetro b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    dj_dw = np.zeros((n,))                           #(n,)\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i],w) + b)          #(n,)(n,)=scalar\n",
    "        err_i  = f_wb_i  - y[i]                       #scalar\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err_i * X[i,j]      #scalar\n",
    "        dj_db = dj_db + err_i\n",
    "    dj_dw = dj_dw/m                                   #(n,)\n",
    "    dj_db = dj_db/m                                   #scalar\n",
    "    \n",
    "    # Com o for abaixo, adicionamos às derivadas a parte que corresponde à regularização\n",
    "    for j in range(n):\n",
    "        dj_dw[j] = dj_dw[j] + (lambda_/m) * w[j]\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892c2dc",
   "metadata": {},
   "source": [
    "Rode o código abaixo para checar a nossa implementação da função `calcula_gradiente_RegLog_com_regu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033ba728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.07138288792343662\n",
      "Primeiros 4 elementos dj_dw regularizado:\n",
      " [-0.010386028450548701, 0.011409852883280122, 0.0536273463274574, 0.003140278267313462]\n"
     ]
    }
   ],
   "source": [
    "X_mapped = mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1) \n",
    "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5 \n",
    "initial_b = 0.5\n",
    " \n",
    "lambda_ = 0.5\n",
    "dj_db, dj_dw = calcula_gradiente_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(f\"dj_db: {dj_db}\", )\n",
    "print(f\"Primeiros 4 elementos dj_dw regularizado:\\n {dj_dw[:4].tolist()}\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4966a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Resultados esperados**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db:</b>0.07138288792343656</td> </tr>\n",
    "  <tr>\n",
    "      <td> <b> Primeiros 4 elementos dj_dw regularizado:</b> </td> </tr>\n",
    "   <tr>\n",
    "   <td> [[-0.010386028450548701], [0.01140985288328012], [0.0536273463274574], [0.003140278267313462]] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2006999",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Método do Gradiente: descrição do código\n",
    "\n",
    "O código que implementa a Equação (1) acima é fornecido abaixo. Tire um momento para entender o que está sendo calculado e como isso é feito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b871c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_do_gradiente_RegLog_com_regu(X, y, w_in, b_in, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performa Método do Gradiente para aprender w e b. Atualiza w e b ao longo de  \n",
    "    num_iters passos de iteração usando uma taxa de aprendizado alpha\n",
    "    \n",
    "    Argumentos:\n",
    "      X (ndarray (m,n))      : Dados, contendo m exemplos com n características\n",
    "      y (ndarray (m,))       : valores alvo\n",
    "      w_in (ndarray (n,))    : valores iniciais dos parâmetros w do modelo  \n",
    "      b_in (escalar)         : valor inicial do parâmetro b do modelo\n",
    "      alpha (float)          : taxa de aprendizado\n",
    "      num_iters (int)        : Número de iterações para o método do gradiente\n",
    "      lambda_(scalar, float) : Constante de Regularização\n",
    "      \n",
    "    Retorna:\n",
    "      w (ndarray (n,)) : Valores atualizados para os parâmetros w\n",
    "      b (scalar)       : Valores atualizado para o parâmetro b \n",
    "      \"\"\"\n",
    "    \n",
    "    # Valores históricos\n",
    "    J_history = []\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculando o gradiente\n",
    "        dj_db, dj_dw = calcula_gradiente_RegLog_com_regu(X, y, w, b, lambda_)   \n",
    "\n",
    "        # Atualizando os parâmetros com base em alpha e nos gradientes\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "        # Salva J para cada iteração\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( calcula_custo_RegLog_com_regu(X, y, w, b, lambda_) )\n",
    "\n",
    "        # Faz o print da função custo de tempos em tempos\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteração {i:4d}: Custo {J_history[-1]}   \")\n",
    "        \n",
    "    return w, b, J_history         #retorna os valores finais w,b e J history para plotar curva de aprendizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456eb65e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vamos agora rodar a Regressão Logística para os nossos dados.\n",
    "- O bloco de código abaixo demora um tempo para rodar, especialmente com uma implementação não vetorizada. Você pode reduzir o número de `iterações` para testar sua implementação mais rapidamente. Se você tiver tempo, rode por 100000 iterações para obter resultados melhores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34664680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração    0: Custo 0.7210188345400221   \n",
      "Iteração 1000: Custo 0.5874629876860554   \n",
      "Iteração 2000: Custo 0.5571493267445516   \n",
      "Iteração 3000: Custo 0.5331852187780525   \n",
      "Iteração 4000: Custo 0.513669211379471   \n",
      "Iteração 5000: Custo 0.49746116535166157   \n",
      "Iteração 6000: Custo 0.4837818783748566   \n",
      "Iteração 7000: Custo 0.47208058644395257   \n",
      "Iteração 8000: Custo 0.46195696269215014   \n",
      "Iteração 9000: Custo 0.45311293975968187   \n",
      "\n",
      "parâmetros finais: w:[ 0.91430359  1.4923378  -2.59208306 -1.0206783  -1.70874963 -0.09508199\n",
      " -0.70729902 -0.45522579 -0.2625241  -1.50258859 -0.14183125 -0.44103606\n",
      " -0.5216627  -0.85782008 -0.62213889 -0.0730526  -0.11749311 -0.22665893\n",
      " -0.62206091 -0.81773062 -0.81412362  0.47440112 -0.48661532  0.20171914\n",
      "  0.03665575  0.27726316 -1.43466503], b:1.43411872285427\n"
     ]
    }
   ],
   "source": [
    "# Inicializando os parâmetros do modelo\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1])-0.5  # atribui um valor inicial aleatório para os parâmetros w_j\n",
    "initial_b = 1.\n",
    "\n",
    "# Definindo o parâmetro de regularização (fique a vontade para variá-lo)\n",
    "lambda_ = 0.01;                                          \n",
    "# Outras definições para o método do gradiente:\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "w_out, b_out, _ = metodo_do_gradiente_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, alpha, iterations, lambda_) \n",
    "print(f\"\\nparâmetros finais: w:{w_out}, b:{b_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a7d1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Resultado Esperado: Custo $<$ 0.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c52731",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotando a Fronteira de Decisão\n",
    "\n",
    "Para lhe auxiliar na visualização do modelo treinado pelo classificador, nós usaremos a nossa função `plota_fronteira_decisao` que plota a fronteira de decisão não linear que separa os exemplos positivos dos negativos.\n",
    "\n",
    "- Na função, nós plotamos a fronteira de decisão não linear computando as previsões do classificador numa grid igualmente espaçada e então desenhamos o gráfico de contorno onde as previsões mudam de y = 0 para y = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a7d8bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plota_fronteira_decisao(w_out, b_out, X_mapped, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8a25c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fazendo previsões:\n",
    "\n",
    "Agora você pode ver as previsões feitas por este modelo chamando a nossa função `probab_e_previsao`. Ela irá fornecer as probabilidades calculadas pelo modelo para cada amostra e então produz as previsões 1 ou 0 com base nessas probabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2a134",
   "metadata": {},
   "source": [
    "- Primeiro, é necessário calcular a probabilidade de $y$ ser 1 a partir do modelo $f(x^{(i)}) = g(w \\cdot x^{(i)}+b)$ para cada amostra. Isso considerando parâmetros $w$ e $b$ para o modelo.\n",
    "- Então, para obter uma previsão final ($y^{(i)}=0$ ou $y^{(i)}=1$) do modelo de regressão logística, nós usamos a seguinte heurística:\n",
    "\n",
    "  se $f(x^{(i)}) >= 0.5$, prever $y^{(i)}=1$\n",
    "  \n",
    "  se $f(x^{(i)}) < 0.5$, prever $y^{(i)}=0$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1156abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probab_e_previsao(X, w, b): \n",
    "    \"\"\"\n",
    "    Prevê se o rótulo é 0 ou 1 usando modelo de regressão logística com parâmetros w e b\n",
    "    \n",
    "    Argumentos:\n",
    "    X : (ndarray Shape (m, n))       Dados\n",
    "    w : (array_like Shape (n,))      Parâmetros do modelo\n",
    "    b : (scalar, float)              Parâmetro do modelo\n",
    "\n",
    "    Retorna:\n",
    "    probab:   (ndarray (m,1))        Probabilidade de y ser 1 para cada amostra\n",
    "    previsao: (ndarray (m,1))        Previsão final para cada amostra usando limiar de 0.5\n",
    "    \"\"\"\n",
    "    # número de amostras de treinamento\n",
    "    m, n     = X.shape   \n",
    "    probab   = np.zeros(m)\n",
    "    previsao = np.zeros(m)\n",
    "   \n",
    "    # passando por cada amostra\n",
    "    for i in range(m):   \n",
    "        z_wb = np.dot(X[i],w) \n",
    "        \n",
    "        # adiciona termo de bias\n",
    "        z_wb += b\n",
    "        \n",
    "        # calcula a probabilidade para esse exemplo\n",
    "        f_wb      = sigmoid(z_wb)\n",
    "        probab[i] = f_wb\n",
    "\n",
    "        # Aplica o valor limiar para geral a previsão final\n",
    "        previsao[i] = 1 if f_wb>0.5 else 0\n",
    "\n",
    "    return probab, previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832a9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73437258 1.        ]\n",
      " [0.75128805 1.        ]\n",
      " [0.72737832 1.        ]\n",
      " [0.74786624 1.        ]\n",
      " [0.65271664 1.        ]\n",
      " [0.61269189 1.        ]\n",
      " [0.66604092 1.        ]\n",
      " [0.62445371 1.        ]\n",
      " [0.63856543 1.        ]\n",
      " [0.58175132 1.        ]\n",
      " [0.53469353 1.        ]\n",
      " [0.50987647 1.        ]\n",
      " [0.5740845  1.        ]\n",
      " [0.45080369 0.        ]\n",
      " [0.65090481 1.        ]\n",
      " [0.75158347 1.        ]\n",
      " [0.81549498 1.        ]\n",
      " [0.57232263 1.        ]\n",
      " [0.72948788 1.        ]\n",
      " [0.63337184 1.        ]\n",
      " [0.51435969 1.        ]\n",
      " [0.51243399 1.        ]\n",
      " [0.45746859 0.        ]\n",
      " [0.48578136 0.        ]\n",
      " [0.5967915  1.        ]\n",
      " [0.50990798 1.        ]\n",
      " [0.53295385 1.        ]\n",
      " [0.3604747  0.        ]\n",
      " [0.81289585 1.        ]\n",
      " [0.60066092 1.        ]\n",
      " [0.1905419  0.        ]\n",
      " [0.59822976 1.        ]\n",
      " [0.76636824 1.        ]\n",
      " [0.79095305 1.        ]\n",
      " [0.75458722 1.        ]\n",
      " [0.72379056 1.        ]\n",
      " [0.65289064 1.        ]\n",
      " [0.73509723 1.        ]\n",
      " [0.76912967 1.        ]\n",
      " [0.66572803 1.        ]\n",
      " [0.75202334 1.        ]\n",
      " [0.71699185 1.        ]\n",
      " [0.60179093 1.        ]\n",
      " [0.77188797 1.        ]\n",
      " [0.65743865 1.        ]\n",
      " [0.70092084 1.        ]\n",
      " [0.40202271 0.        ]\n",
      " [0.81023494 1.        ]\n",
      " [0.58139224 1.        ]\n",
      " [0.64792193 1.        ]\n",
      " [0.80562642 1.        ]\n",
      " [0.84581314 1.        ]\n",
      " [0.81665314 1.        ]\n",
      " [0.81643321 1.        ]\n",
      " [0.79731541 1.        ]\n",
      " [0.69118335 1.        ]\n",
      " [0.74603685 1.        ]\n",
      " [0.66652156 1.        ]\n",
      " [0.19851062 0.        ]\n",
      " [0.56212119 1.        ]\n",
      " [0.73587074 1.        ]\n",
      " [0.3561087  0.        ]\n",
      " [0.26448711 0.        ]\n",
      " [0.47445845 0.        ]\n",
      " [0.27711237 0.        ]\n",
      " [0.0761452  0.        ]\n",
      " [0.27638102 0.        ]\n",
      " [0.06767639 0.        ]\n",
      " [0.09606838 0.        ]\n",
      " [0.21839053 0.        ]\n",
      " [0.13969391 0.        ]\n",
      " [0.17652718 0.        ]\n",
      " [0.15297576 0.        ]\n",
      " [0.18161191 0.        ]\n",
      " [0.24679587 0.        ]\n",
      " [0.45249657 0.        ]\n",
      " [0.6181627  1.        ]\n",
      " [0.52792837 1.        ]\n",
      " [0.31225405 0.        ]\n",
      " [0.31084531 0.        ]\n",
      " [0.52499607 1.        ]\n",
      " [0.54987022 1.        ]\n",
      " [0.39573885 0.        ]\n",
      " [0.52040125 1.        ]\n",
      " [0.15828071 0.        ]\n",
      " [0.33026007 0.        ]\n",
      " [0.3064693  0.        ]\n",
      " [0.32266109 0.        ]\n",
      " [0.63378833 1.        ]\n",
      " [0.2647293  0.        ]\n",
      " [0.22751387 0.        ]\n",
      " [0.50705504 1.        ]\n",
      " [0.61358609 1.        ]\n",
      " [0.28390923 0.        ]\n",
      " [0.12971313 0.        ]\n",
      " [0.01021252 0.        ]\n",
      " [0.00671897 0.        ]\n",
      " [0.33041952 0.        ]\n",
      " [0.04521553 0.        ]\n",
      " [0.07675225 0.        ]\n",
      " [0.30362548 0.        ]\n",
      " [0.00821133 0.        ]\n",
      " [0.46991213 0.        ]\n",
      " [0.31958279 0.        ]\n",
      " [0.60177444 1.        ]\n",
      " [0.40048123 0.        ]\n",
      " [0.52829962 1.        ]\n",
      " [0.69765069 1.        ]\n",
      " [0.40071901 0.        ]\n",
      " [0.26299285 0.        ]\n",
      " [0.21953757 0.        ]\n",
      " [0.24352328 0.        ]\n",
      " [0.1911803  0.        ]\n",
      " [0.35846996 0.        ]\n",
      " [0.55996821 1.        ]\n",
      " [0.07756392 0.        ]\n",
      " [0.10598459 0.        ]\n",
      " [0.64006767 1.        ]]\n",
      "Taxa de acerto para dados de treinamento: 82.203390\n"
     ]
    }
   ],
   "source": [
    "# Calculando probalidade e previsão correspondente para cada amostra do conjunto de dados de treinamento\n",
    "probab, previsao = probab_e_previsao(X_mapped, w_out, b_out)\n",
    "\n",
    "print(np.c_[probab, previsao])\n",
    "\n",
    "print('Taxa de acerto para dados de treinamento: %f'%(np.mean(previsao == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57b80f",
   "metadata": {},
   "source": [
    "**Resultado Esperado**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Taxa de acerto para dados de treinamento:</b>~ 80%</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8311c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parabéns!\n",
    "\n",
    "Com este código você implementou o algoritmo de Regressão Logística com Regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566aadf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
