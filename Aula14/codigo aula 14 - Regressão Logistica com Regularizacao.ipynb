{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9623a828",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regress√£o Log√≠stica com Regulariza√ß√£o\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Com este c√≥digo, voc√™ ir√°:\n",
    "- Modificar as fun√ß√µes do nosso c√≥digo anterior, para agora contemplar a Regulariza√ß√£o.\n",
    "- Note que testaremos nosso algoritmo regularizado num novo conjunto de dados que exigir√° a adi√ß√£o de termos polinomiais ao modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b54c01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nossa_biblioteca_de_funcoes import *   # Importando as fun√ß√µes auxiliares que usaremos nesse c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9232",
   "metadata": {},
   "source": [
    "Neste c√≥digo, voc√™ implementar√° a Regress√£o Log√≠stica com Regulariza√ß√£o para prever se os microchips de uma f√°brica passam num determinado teste de garantia de qualidade (GQ). Durante tal teste de GQ, cada microchip passa por diversos testes que garantem que ele est√° funcionando corretamente.\n",
    "\n",
    "### Defini√ß√£o do Problema\n",
    "\n",
    "Suponha que voc√™ seja o gerente de produto de uma f√°brica e voc√™ t√™m acesso aos resultados para dois diferentes testes realizados nos microchips\n",
    "- Destes dois testes, voc√™ gostaria de determinar se os chips devem ser aprovados ou rejeitados\n",
    "- Para ajudar na sua tomada de decis√£o, voc√™ tem um banco de dados contendo os resultados de microchips passados. Voc√™ usar√° esses dados para construir um modelo de Regress√£o Log√≠stica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e641497",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Carregando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67073772",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('dados_microchip.txt') # As duas primeiras colunas referem-se √†s caracter√≠sticas -> resultados obtidos pelos microchips nos teste 1 e 2\n",
    "                                   # A terceira (√∫ltima) coluna refere-se ao resultado do teste de GQ (1 significa chip aprovado)\n",
    "dados = np.loadtxt(file, delimiter=\",\") \n",
    "\n",
    "X_train = dados[:,0:2]\n",
    "y_train = dados[:,-1] # pega apenas a √∫ltima coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19f90",
   "metadata": {},
   "source": [
    "Vizualizando numericamente os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934ebccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 0.051267  0.69956 ]\n",
      " [-0.092742  0.68494 ]\n",
      " [-0.21371   0.69225 ]\n",
      " [-0.375     0.50219 ]\n",
      " [-0.51325   0.46564 ]]\n",
      "Tipo do X_train: <class 'numpy.ndarray'>\n",
      "y_train: [1. 1. 1. 1. 1.]\n",
      "Tipo do y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print X_train\n",
    "print(\"X_train:\", X_train[:5])\n",
    "print(\"Tipo do X_train:\",type(X_train))\n",
    "\n",
    "# print y_train\n",
    "print(\"y_train:\", y_train[:5])\n",
    "print(\"Tipo do y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f55a3",
   "metadata": {},
   "source": [
    "#### Cheque as dimens√µes das suas vari√°veis\n",
    "\n",
    "\n",
    "Uma outra forma √∫til para se familizarizar com os dados √© visualizar suas dimens√µes.\n",
    "Vamos dar print dos shapes de `X_train` e `y_train`para verificar quantas amostras de treinamento n√≥s temos no nosso conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd374b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O shape de X_train √©: (118, 2)\n",
      "O shape de y_train √©: (118,)\n",
      "N√≥s temos 118 exemplos (amostras) de treinamento\n"
     ]
    }
   ],
   "source": [
    "print ('O shape de X_train √©: ' + str(X_train.shape))\n",
    "print ('O shape de y_train √©: ' + str(y_train.shape))\n",
    "print ('N√≥s temos %d exemplos (amostras) de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cd102",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plotando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f392f8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = y_train == 1 # identifica os elementos em y que s√£o iguais a 1\n",
    "neg = y_train == 0 # identifica os elementos em y que s√£o iguais a 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "ax.plot(X_train[pos,0], X_train[pos,1], 'k+', label=\"Aprovado\")\n",
    "ax.plot(X_train[neg,0], X_train[neg,1], 'yo', label=\"Reprovado\")\n",
    "\n",
    "#ax.axis([0, 4, 0, 3.5])\n",
    "ax.set_ylabel('Teste 2 no microchip')\n",
    "ax.set_xlabel('Teste 1 no microchip')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd93be5",
   "metadata": {},
   "source": [
    "A figura acima mostra que nosso conjunto de dados n√£o pode ser separado em amostras positivas e negativas usando uma reta. Logo, uma aplica√ß√£o direta da Regress√£o Log√≠stica n√£o ir√° performar bem nesse conjunto de dados umas vez que a Regress√£o Log√≠stica n√£o conseguir√° encontrar uma Fronteira de Decis√£o linear adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19759b8",
   "metadata": {},
   "source": [
    "### Mapeamento de caracter√≠sticas\n",
    "\n",
    "\n",
    "Uma forma de ajustar os dados melhor √© criar mais caracter√≠sticas para cada amostra. Na fun√ß√£o `mapeia_caracteristicas`, n√≥s vamos mapear as caracter√≠sticas para todos os termos polinomiais de $x_1$ e $x_2$ at√© a sexta pot√™ncia.\n",
    "\n",
    "$$\\mathrm{mapeia\\_caracteristicas}(x) = \n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_1^2\\\\\n",
    "x_1 x_2\\\\\n",
    "x_2^2\\\\\n",
    "x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1 x_2^5\\\\\n",
    "x_2^6\\end{array}\\right]$$\n",
    "\n",
    "Como um resultado desse mapeamento, nosso vetor de duas caracter√≠sticas (as pontua√ß√µes nos dois testes) foi transformado em um vetor de 27 dimens√µes.\n",
    "- Um classificador de regress√£o log√≠stica treinado para essa dimens√£o elevada ter√° uma fronteira de decis√£o complexa e ser√° n√£o linear ao plotarmos ela num gr√°fico com 2 dimens√µes.\n",
    "- A fun√ß√£o `mapeia_caracteristicas` est√° sendo fornecida (n√£o √© necess√°rio program√°-la) dentro do arquivo nossa_biblioteca_de_funcoes.py. \n",
    "- Visite o arquivo nossa_biblioteca_de_funcoes.py para ver como a fun√ß√£o `mapeia_caracteristicas` foi escrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a1730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original dos dados: (118, 2)\n",
      "Shape ap√≥s o mapeamento de caracter√≠sticas: (118, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape original dos dados:\", X_train.shape)\n",
    "\n",
    "mapped_X =  mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "print(\"Shape ap√≥s o mapeamento de caracter√≠sticas:\", mapped_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a788b",
   "metadata": {},
   "source": [
    "Vamos tamb√©m plotar os primeiros elementos de `X_train` e `mapped_X` para vermos a transforma√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbd5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0.051267 0.69956 ]\n",
      "mapped X_train[0]: [5.12670000e-02 6.99560000e-01 2.62830529e-03 3.58643425e-02\n",
      " 4.89384194e-01 1.34745327e-04 1.83865725e-03 2.50892595e-02\n",
      " 3.42353606e-01 6.90798869e-06 9.42624411e-05 1.28625106e-03\n",
      " 1.75514423e-02 2.39496889e-01 3.54151856e-07 4.83255257e-06\n",
      " 6.59422333e-05 8.99809795e-04 1.22782870e-02 1.67542444e-01\n",
      " 1.81563032e-08 2.47750473e-07 3.38066048e-06 4.61305487e-05\n",
      " 6.29470940e-04 8.58939846e-03 1.17205992e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"mapped X_train[0]:\", mapped_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96b9dd",
   "metadata": {},
   "source": [
    "Uma vez que o mapeamento de caracter√≠sticas nos permite construir um classificador mais expressivo, ele tamb√©m est√° mais suscet√≠vel ao overfitting. Para lidar com esse problema, a seguir n√≥s implementamos o m√©todo de Regress√£o Log√≠stica com Regulariza√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40f6d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fun√ß√£o Custo com Regulariza√ß√£o\n",
    "\n",
    "Na Regress√£o Log√≠stica com regulariza√ß√£o, a fun√ß√£o custo tem a forma \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2 \\tag{1}$$\n",
    "\n",
    "onde    \n",
    "*  m √© o n√∫mero de amostras de treinamento, n √© o n√∫mero de caracter√≠sticas e:\n",
    "$$\n",
    "\\begin{align}\n",
    "  f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) &= g(z^{(i)})\\tag{3} \\\\\n",
    "  z^{(i)} &= \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+ b\\tag{4} \\\\\n",
    "  g(z^{(i)}) &= \\frac{1}{1+e^{-z^{(i)}}}\\tag{5} \n",
    "\\end{align}\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64a3ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Descri√ß√£o do C√≥digo abaixo:\n",
    "\n",
    "A fun√ß√£o `calcula_custo_RegLog` abaixo faz um loop passando por todas as amostras e calculando a perda para cada exemplo.\n",
    "O total ent√£o √© computado e depois divido por m. Por fim, o termo relativo √† Regulariza√ß√£o √© adicionado\n",
    "\n",
    "Note que as vari√°veis X e y n√£o s√£o escalares mas sim matrizes de shape ($m, n$) e ($ùëö$,) respectivamente, onde  $ùëõ$ √© o n√∫mero de caracter√≠sticas e $ùëö$ √© o n√∫mero de amostras de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63409143",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcula_custo_RegLog_com_regu(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Calcula a fun√ß√£o custo para Regress√£o Log√≠stica com Regulariza√ß√£o\n",
    "\n",
    "    Argumentos:\n",
    "      X (ndarray (m,n)): Dados, m exemplos com n caracter√≠sticas\n",
    "      y (ndarray (m,)) : valores alvo\n",
    "      w (ndarray (n,)) : par√¢metros do modelo  \n",
    "      b (escalar)      : par√¢metro do modelo\n",
    "      lambda_ : (escalar, float):    Controla a quantidade de regulariza√ß√£o presente no modelo (default = 1)\n",
    "      \n",
    "    Retorna:\n",
    "      custo (escalar): custo\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]\n",
    "    custo = 0.0\n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i],w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        custo +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)\n",
    "         \n",
    "    custo = custo / m\n",
    "    \n",
    "    # Abaixo calculamos o termo (custo) associado √† regulariza√ß√£o:\n",
    "    custo_reg =  (lambda_/(2 * m))*sum(np.square(w))\n",
    "            \n",
    "    custo = custo + custo_reg\n",
    "    \n",
    "    return custo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d49986",
   "metadata": {},
   "source": [
    "Rode o c√≥digo abaixo para checar a nossa implementa√ß√£o da fun√ß√£o `calcula_custo_RegLog_com_regu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b836732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo regularizado : 0.6618252552483948\n"
     ]
    }
   ],
   "source": [
    "X_mapped = mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5  # O que este comando faz?\n",
    "initial_b = 0.5\n",
    "lambda_   = 0.5\n",
    "custo     = calcula_custo_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(\"Custo regularizado :\", custo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8a41a",
   "metadata": {},
   "source": [
    "**Resultado esperado**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo regularizado : <b></td>\n",
    "    <td> 0.6618252552483948 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da3ef7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# M√©todo do Gradiente com Regulariza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25268a92",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Lembre-se que o M√©todo do Gradiente implementa a seguinte l√≥gica:\n",
    "$$\\begin{align*}\n",
    "&\\text{repetir at√© convergir:} \\; \\lbrace \\\\\n",
    "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{para j := 0..n-1} \\\\ \n",
    "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\\\\n",
    "&\\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "Onde cada itera√ß√£o performa atualiza√ß√£o simultanea de $w_j$ para todo $j$ e para $b$, onde\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\left( \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j  \\tag{2} \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3} \n",
    "\\end{align*}$$\n",
    "\n",
    "* $f_{\\mathbf{w},b}(x^{(i)})$ √© a previs√£o feita pelo modelo, sendo $y^{(i)}$ o alvo\n",
    "* Para o modelo de Regress√£o Log√≠stica:\n",
    "    $z = \\mathbf{w} \\cdot \\mathbf{x} + b$  \n",
    "    $f_{\\mathbf{w},b}(x) = g(z)$  \n",
    "    sendo $g(z)$ a fun√ß√£o sigmoide:  \n",
    "    $g(z) = \\frac{1}{1+e^{-z}}$   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f868b74",
   "metadata": {},
   "source": [
    "## Implementa√ß√£o do M√©todo do Gradiente:\n",
    "\n",
    "O algoritmo do M√©todo do Gradiente possui duas componentes: \n",
    "- O loop que implementa a equa√ß√£o (1) acima. Essa √© a fun√ß√£o metodo_do_gradiente_RegLog_com_regu abaixo.\n",
    "- O c√°lculo do gradiente atual, dado pelas equa√ß√µes (2) e (3) acima. Essa √© a fun√ß√£o calcula_gradiente_RegLog_com_regu abaixo.\n",
    "\n",
    "#### C√°lculo do gradiente: descri√ß√£o do c√≥digo:\n",
    "Implementa as equa√ß√µes (2) e (3) acima para todo $w_j$ e $b$.\n",
    "\n",
    "H√° muitas formas para se implementar isso. Abaixo fazemos da seguinte maneira:\n",
    "- Inicializamos as vari√°veis para acumular `dj_dw` e `dj_db`\n",
    "- Para cada exemplo:\n",
    "    - Calcula-se o erro para esse exemplo, $g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b) - \\mathbf{y}^{(i)}$\n",
    "    - Para cada valor de entrada $x_{j}^{(i)}$ nesse exemplo,  \n",
    "        - multiplica o erro pela entrada  $x_{j}^{(i)}$, e adiciona ao elemento correspondente de `dj_dw`. (Equa√ß√£o 2 acima)\n",
    "    - adiciona o erro para `dj_db` (Equa√ß√£o 3 acima)\n",
    "\n",
    "- divide-se `dj_db` e `dj_dw` pelo n√∫mero total de amostras (m)\n",
    "- Note que $\\mathbf{x}^{(i)}$ em Numpy √© `X[i,:]` ou `X[i]`  e que $x_{j}^{(i)}$ √© `X[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05ef97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_gradiente_RegLog_com_regu(X, y, w, b, lambda_ = 1): \n",
    "    \"\"\"\n",
    "    Calcula Gradiente para Regress√£o Linear\n",
    "    Argumentos:\n",
    "      X (ndarray (m,n)): Dados, contendo m exemplos com n caracter√≠sticas\n",
    "      y (ndarray (m,)) : valores alvo\n",
    "      w (ndarray (n,)) : par√¢metros w do modelo  \n",
    "      b (scalar)       : par√¢metro b do modelo\n",
    "      lambda_ : (escalar, float):    Controla a quantidade de regulariza√ß√£o presente no modelo (default = 1)\n",
    "      \n",
    "    Retorna:\n",
    "      dj_dw (ndarray (n,)): O gradiente da fun√ß√£o custo com rela√ß√£o aos par√¢metros w. \n",
    "      dj_db (escalar):      O gradiente da fun√ß√£o custo com rela√ß√£o ao par√¢metro b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    dj_dw = np.zeros((n,))                           #(n,)\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i],w) + b)          #(n,)(n,)=scalar\n",
    "        err_i  = f_wb_i  - y[i]                       #scalar\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err_i * X[i,j]      #scalar\n",
    "        dj_db = dj_db + err_i\n",
    "    dj_dw = dj_dw/m                                   #(n,)\n",
    "    dj_db = dj_db/m                                   #scalar\n",
    "    \n",
    "    # Com o for abaixo, adicionamos √†s derivadas a parte que corresponde √† regulariza√ß√£o\n",
    "    for j in range(n):\n",
    "        dj_dw[j] = dj_dw[j] + (lambda_/m) * w[j]\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892c2dc",
   "metadata": {},
   "source": [
    "Rode o c√≥digo abaixo para checar a nossa implementa√ß√£o da fun√ß√£o `calcula_gradiente_RegLog_com_regu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033ba728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.07138288792343662\n",
      "Primeiros 4 elementos dj_dw regularizado:\n",
      " [-0.010386028450548701, 0.011409852883280122, 0.0536273463274574, 0.003140278267313462]\n"
     ]
    }
   ],
   "source": [
    "X_mapped = mapeia_caracteristicas(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1) \n",
    "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5 \n",
    "initial_b = 0.5\n",
    " \n",
    "lambda_ = 0.5\n",
    "dj_db, dj_dw = calcula_gradiente_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(f\"dj_db: {dj_db}\", )\n",
    "print(f\"Primeiros 4 elementos dj_dw regularizado:\\n {dj_dw[:4].tolist()}\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4966a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Resultados esperados**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db:</b>0.07138288792343656</td> </tr>\n",
    "  <tr>\n",
    "      <td> <b> Primeiros 4 elementos dj_dw regularizado:</b> </td> </tr>\n",
    "   <tr>\n",
    "   <td> [[-0.010386028450548701], [0.01140985288328012], [0.0536273463274574], [0.003140278267313462]] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2006999",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### M√©todo do Gradiente: descri√ß√£o do c√≥digo\n",
    "\n",
    "O c√≥digo que implementa a Equa√ß√£o (1) acima √© fornecido abaixo. Tire um momento para entender o que est√° sendo calculado e como isso √© feito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b871c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_do_gradiente_RegLog_com_regu(X, y, w_in, b_in, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performa M√©todo do Gradiente para aprender w e b. Atualiza w e b ao longo de  \n",
    "    num_iters passos de itera√ß√£o usando uma taxa de aprendizado alpha\n",
    "    \n",
    "    Argumentos:\n",
    "      X (ndarray (m,n))      : Dados, contendo m exemplos com n caracter√≠sticas\n",
    "      y (ndarray (m,))       : valores alvo\n",
    "      w_in (ndarray (n,))    : valores iniciais dos par√¢metros w do modelo  \n",
    "      b_in (escalar)         : valor inicial do par√¢metro b do modelo\n",
    "      alpha (float)          : taxa de aprendizado\n",
    "      num_iters (int)        : N√∫mero de itera√ß√µes para o m√©todo do gradiente\n",
    "      lambda_(scalar, float) : Constante de Regulariza√ß√£o\n",
    "      \n",
    "    Retorna:\n",
    "      w (ndarray (n,)) : Valores atualizados para os par√¢metros w\n",
    "      b (scalar)       : Valores atualizado para o par√¢metro b \n",
    "      \"\"\"\n",
    "    \n",
    "    # Valores hist√≥ricos\n",
    "    J_history = []\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculando o gradiente\n",
    "        dj_db, dj_dw = calcula_gradiente_RegLog_com_regu(X, y, w, b, lambda_)   \n",
    "\n",
    "        # Atualizando os par√¢metros com base em alpha e nos gradientes\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "        # Salva J para cada itera√ß√£o\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( calcula_custo_RegLog_com_regu(X, y, w, b, lambda_) )\n",
    "\n",
    "        # Faz o print da fun√ß√£o custo de tempos em tempos\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Itera√ß√£o {i:4d}: Custo {J_history[-1]}   \")\n",
    "        \n",
    "    return w, b, J_history         #retorna os valores finais w,b e J history para plotar curva de aprendizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456eb65e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vamos agora rodar a Regress√£o Log√≠stica para os nossos dados.\n",
    "- O bloco de c√≥digo abaixo demora um tempo para rodar, especialmente com uma implementa√ß√£o n√£o vetorizada. Voc√™ pode reduzir o n√∫mero de `itera√ß√µes` para testar sua implementa√ß√£o mais rapidamente. Se voc√™ tiver tempo, rode por 100000 itera√ß√µes para obter resultados melhores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34664680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itera√ß√£o    0: Custo 0.7210188345400221   \n",
      "Itera√ß√£o 1000: Custo 0.5874629876860554   \n",
      "Itera√ß√£o 2000: Custo 0.5571493267445516   \n",
      "Itera√ß√£o 3000: Custo 0.5331852187780525   \n",
      "Itera√ß√£o 4000: Custo 0.513669211379471   \n",
      "Itera√ß√£o 5000: Custo 0.49746116535166157   \n",
      "Itera√ß√£o 6000: Custo 0.4837818783748566   \n",
      "Itera√ß√£o 7000: Custo 0.47208058644395257   \n",
      "Itera√ß√£o 8000: Custo 0.46195696269215014   \n",
      "Itera√ß√£o 9000: Custo 0.45311293975968187   \n",
      "\n",
      "par√¢metros finais: w:[ 0.91430359  1.4923378  -2.59208306 -1.0206783  -1.70874963 -0.09508199\n",
      " -0.70729902 -0.45522579 -0.2625241  -1.50258859 -0.14183125 -0.44103606\n",
      " -0.5216627  -0.85782008 -0.62213889 -0.0730526  -0.11749311 -0.22665893\n",
      " -0.62206091 -0.81773062 -0.81412362  0.47440112 -0.48661532  0.20171914\n",
      "  0.03665575  0.27726316 -1.43466503], b:1.43411872285427\n"
     ]
    }
   ],
   "source": [
    "# Inicializando os par√¢metros do modelo\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1])-0.5  # atribui um valor inicial aleat√≥rio para os par√¢metros w_j\n",
    "initial_b = 1.\n",
    "\n",
    "# Definindo o par√¢metro de regulariza√ß√£o (fique a vontade para vari√°-lo)\n",
    "lambda_ = 0.01;                                          \n",
    "# Outras defini√ß√µes para o m√©todo do gradiente:\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "w_out, b_out, _ = metodo_do_gradiente_RegLog_com_regu(X_mapped, y_train, initial_w, initial_b, alpha, iterations, lambda_) \n",
    "print(f\"\\npar√¢metros finais: w:{w_out}, b:{b_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a7d1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Resultado Esperado: Custo $<$ 0.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c52731",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotando a Fronteira de Decis√£o\n",
    "\n",
    "Para lhe auxiliar na visualiza√ß√£o do modelo treinado pelo classificador, n√≥s usaremos a nossa fun√ß√£o `plota_fronteira_decisao` que plota a fronteira de decis√£o n√£o linear que separa os exemplos positivos dos negativos.\n",
    "\n",
    "- Na fun√ß√£o, n√≥s plotamos a fronteira de decis√£o n√£o linear computando as previs√µes do classificador numa grid igualmente espa√ßada e ent√£o desenhamos o gr√°fico de contorno onde as previs√µes mudam de y = 0 para y = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a7d8bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plota_fronteira_decisao(w_out, b_out, X_mapped, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8a25c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fazendo previs√µes:\n",
    "\n",
    "Agora voc√™ pode ver as previs√µes feitas por este modelo chamando a nossa fun√ß√£o `probab_e_previsao`. Ela ir√° fornecer as probabilidades calculadas pelo modelo para cada amostra e ent√£o produz as previs√µes 1 ou 0 com base nessas probabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2a134",
   "metadata": {},
   "source": [
    "- Primeiro, √© necess√°rio calcular a probabilidade de $y$ ser 1 a partir do modelo $f(x^{(i)}) = g(w \\cdot x^{(i)}+b)$ para cada amostra. Isso considerando par√¢metros $w$ e $b$ para o modelo.\n",
    "- Ent√£o, para obter uma previs√£o final ($y^{(i)}=0$ ou $y^{(i)}=1$) do modelo de regress√£o log√≠stica, n√≥s usamos a seguinte heur√≠stica:\n",
    "\n",
    "  se $f(x^{(i)}) >= 0.5$, prever $y^{(i)}=1$\n",
    "  \n",
    "  se $f(x^{(i)}) < 0.5$, prever $y^{(i)}=0$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1156abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probab_e_previsao(X, w, b): \n",
    "    \"\"\"\n",
    "    Prev√™ se o r√≥tulo √© 0 ou 1 usando modelo de regress√£o log√≠stica com par√¢metros w e b\n",
    "    \n",
    "    Argumentos:\n",
    "    X : (ndarray Shape (m, n))       Dados\n",
    "    w : (array_like Shape (n,))      Par√¢metros do modelo\n",
    "    b : (scalar, float)              Par√¢metro do modelo\n",
    "\n",
    "    Retorna:\n",
    "    probab:   (ndarray (m,1))        Probabilidade de y ser 1 para cada amostra\n",
    "    previsao: (ndarray (m,1))        Previs√£o final para cada amostra usando limiar de 0.5\n",
    "    \"\"\"\n",
    "    # n√∫mero de amostras de treinamento\n",
    "    m, n     = X.shape   \n",
    "    probab   = np.zeros(m)\n",
    "    previsao = np.zeros(m)\n",
    "   \n",
    "    # passando por cada amostra\n",
    "    for i in range(m):   \n",
    "        z_wb = np.dot(X[i],w) \n",
    "        \n",
    "        # adiciona termo de bias\n",
    "        z_wb += b\n",
    "        \n",
    "        # calcula a probabilidade para esse exemplo\n",
    "        f_wb      = sigmoid(z_wb)\n",
    "        probab[i] = f_wb\n",
    "\n",
    "        # Aplica o valor limiar para geral a previs√£o final\n",
    "        previsao[i] = 1 if f_wb>0.5 else 0\n",
    "\n",
    "    return probab, previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832a9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73437258 1.        ]\n",
      " [0.75128805 1.        ]\n",
      " [0.72737832 1.        ]\n",
      " [0.74786624 1.        ]\n",
      " [0.65271664 1.        ]\n",
      " [0.61269189 1.        ]\n",
      " [0.66604092 1.        ]\n",
      " [0.62445371 1.        ]\n",
      " [0.63856543 1.        ]\n",
      " [0.58175132 1.        ]\n",
      " [0.53469353 1.        ]\n",
      " [0.50987647 1.        ]\n",
      " [0.5740845  1.        ]\n",
      " [0.45080369 0.        ]\n",
      " [0.65090481 1.        ]\n",
      " [0.75158347 1.        ]\n",
      " [0.81549498 1.        ]\n",
      " [0.57232263 1.        ]\n",
      " [0.72948788 1.        ]\n",
      " [0.63337184 1.        ]\n",
      " [0.51435969 1.        ]\n",
      " [0.51243399 1.        ]\n",
      " [0.45746859 0.        ]\n",
      " [0.48578136 0.        ]\n",
      " [0.5967915  1.        ]\n",
      " [0.50990798 1.        ]\n",
      " [0.53295385 1.        ]\n",
      " [0.3604747  0.        ]\n",
      " [0.81289585 1.        ]\n",
      " [0.60066092 1.        ]\n",
      " [0.1905419  0.        ]\n",
      " [0.59822976 1.        ]\n",
      " [0.76636824 1.        ]\n",
      " [0.79095305 1.        ]\n",
      " [0.75458722 1.        ]\n",
      " [0.72379056 1.        ]\n",
      " [0.65289064 1.        ]\n",
      " [0.73509723 1.        ]\n",
      " [0.76912967 1.        ]\n",
      " [0.66572803 1.        ]\n",
      " [0.75202334 1.        ]\n",
      " [0.71699185 1.        ]\n",
      " [0.60179093 1.        ]\n",
      " [0.77188797 1.        ]\n",
      " [0.65743865 1.        ]\n",
      " [0.70092084 1.        ]\n",
      " [0.40202271 0.        ]\n",
      " [0.81023494 1.        ]\n",
      " [0.58139224 1.        ]\n",
      " [0.64792193 1.        ]\n",
      " [0.80562642 1.        ]\n",
      " [0.84581314 1.        ]\n",
      " [0.81665314 1.        ]\n",
      " [0.81643321 1.        ]\n",
      " [0.79731541 1.        ]\n",
      " [0.69118335 1.        ]\n",
      " [0.74603685 1.        ]\n",
      " [0.66652156 1.        ]\n",
      " [0.19851062 0.        ]\n",
      " [0.56212119 1.        ]\n",
      " [0.73587074 1.        ]\n",
      " [0.3561087  0.        ]\n",
      " [0.26448711 0.        ]\n",
      " [0.47445845 0.        ]\n",
      " [0.27711237 0.        ]\n",
      " [0.0761452  0.        ]\n",
      " [0.27638102 0.        ]\n",
      " [0.06767639 0.        ]\n",
      " [0.09606838 0.        ]\n",
      " [0.21839053 0.        ]\n",
      " [0.13969391 0.        ]\n",
      " [0.17652718 0.        ]\n",
      " [0.15297576 0.        ]\n",
      " [0.18161191 0.        ]\n",
      " [0.24679587 0.        ]\n",
      " [0.45249657 0.        ]\n",
      " [0.6181627  1.        ]\n",
      " [0.52792837 1.        ]\n",
      " [0.31225405 0.        ]\n",
      " [0.31084531 0.        ]\n",
      " [0.52499607 1.        ]\n",
      " [0.54987022 1.        ]\n",
      " [0.39573885 0.        ]\n",
      " [0.52040125 1.        ]\n",
      " [0.15828071 0.        ]\n",
      " [0.33026007 0.        ]\n",
      " [0.3064693  0.        ]\n",
      " [0.32266109 0.        ]\n",
      " [0.63378833 1.        ]\n",
      " [0.2647293  0.        ]\n",
      " [0.22751387 0.        ]\n",
      " [0.50705504 1.        ]\n",
      " [0.61358609 1.        ]\n",
      " [0.28390923 0.        ]\n",
      " [0.12971313 0.        ]\n",
      " [0.01021252 0.        ]\n",
      " [0.00671897 0.        ]\n",
      " [0.33041952 0.        ]\n",
      " [0.04521553 0.        ]\n",
      " [0.07675225 0.        ]\n",
      " [0.30362548 0.        ]\n",
      " [0.00821133 0.        ]\n",
      " [0.46991213 0.        ]\n",
      " [0.31958279 0.        ]\n",
      " [0.60177444 1.        ]\n",
      " [0.40048123 0.        ]\n",
      " [0.52829962 1.        ]\n",
      " [0.69765069 1.        ]\n",
      " [0.40071901 0.        ]\n",
      " [0.26299285 0.        ]\n",
      " [0.21953757 0.        ]\n",
      " [0.24352328 0.        ]\n",
      " [0.1911803  0.        ]\n",
      " [0.35846996 0.        ]\n",
      " [0.55996821 1.        ]\n",
      " [0.07756392 0.        ]\n",
      " [0.10598459 0.        ]\n",
      " [0.64006767 1.        ]]\n",
      "Taxa de acerto para dados de treinamento: 82.203390\n"
     ]
    }
   ],
   "source": [
    "# Calculando probalidade e previs√£o correspondente para cada amostra do conjunto de dados de treinamento\n",
    "probab, previsao = probab_e_previsao(X_mapped, w_out, b_out)\n",
    "\n",
    "print(np.c_[probab, previsao])\n",
    "\n",
    "print('Taxa de acerto para dados de treinamento: %f'%(np.mean(previsao == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57b80f",
   "metadata": {},
   "source": [
    "**Resultado Esperado**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Taxa de acerto para dados de treinamento:</b>~ 80%</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8311c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parab√©ns!\n",
    "\n",
    "Com este c√≥digo voc√™ implementou o algoritmo de Regress√£o Log√≠stica com Regulariza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566aadf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
